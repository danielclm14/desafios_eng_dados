# CNAB200 - Processamento, ValidaÃ§Ã£o e PersistÃªncia

## ğŸ“Œ DescriÃ§Ã£o do Projeto
Este projeto tem como objetivo processar arquivos **CNAB200** contendo registros de pagamentos. A soluÃ§Ã£o envolve:
- **Parsing do arquivo CNAB200** para extrair e validar os dados.
- **PersistÃªncia dos pagamentos** em um banco de dados relacional (**PostgreSQL**).
- **PublicaÃ§Ã£o dos dados** em uma soluÃ§Ã£o centralizada (**Apache Kafka**).
- **OrquestraÃ§Ã£o** com **Dagster** para garantir execuÃ§Ã£o automÃ¡tica.
- **Monitoramento** usando **Prometheus, Grafana e Logging estruturado**.

A implementaÃ§Ã£o foi feita **prioritariamente em Python**, utilizando bibliotecas como **Pydantic, SQLAlchemy, Kafka-python e Dagster**.

---

## ğŸš€ Tecnologias Utilizadas

| Tecnologia    | Uso no Projeto |
|--------------|---------------|
| Python 3.x   | Linguagem principal |
| PostgreSQL   | Banco de dados relacional |
| Apache Kafka | Mensageria para distribuiÃ§Ã£o dos pagamentos |
| SQLAlchemy   | ORM para interaÃ§Ã£o com PostgreSQL |
| Pydantic     | ValidaÃ§Ã£o de dados CNAB200 |
| Kafka-Python | PublicaÃ§Ã£o de mensagens no Kafka |
| Dagster      | OrquestraÃ§Ã£o de pipelines |
| Prometheus   | Monitoramento do sistema |
| Grafana      | Dashboard de mÃ©tricas |
| Metabase     | VisualizaÃ§Ã£o dos pagamentos |
| Docker       | Infraestrutura containerizada |

---

## ğŸ“ Estrutura do Projeto

```
ğŸ“‚ cnab200_project
 â”œâ”€â”€ ğŸ“‚ data                # Pasta de arquivos CNAB200
 â”œâ”€â”€ ğŸ“‚ dags                # Scripts de pipelines Dagster
 â”œâ”€â”€ ğŸ“‚ db                  # ConfiguraÃ§Ãµes do PostgreSQL
 â”œâ”€â”€ ğŸ“‚ kafka               # ConfiguraÃ§Ã£o do Kafka
 â”œâ”€â”€ cnab200_parser.py      # CÃ³digo principal de processamento
 â”œâ”€â”€ docker-compose.yml     # ConfiguraÃ§Ã£o dos serviÃ§os Docker
 â”œâ”€â”€ README.md              # DocumentaÃ§Ã£o do projeto
 â”œâ”€â”€ requirements.txt       # DependÃªncias do projeto
```

---

## ğŸ“– Etapas do Desenvolvimento

### **1ï¸âƒ£ Parsing do CNAB200**
- Utilizamos **slicing de strings** para extrair campos com base nas posiÃ§Ãµes fixas do arquivo.
- O modelo **Pydantic** garante que os valores sejam corretamente convertidos (**datas, valores, CPF/CNPJ**).

### **2ï¸âƒ£ ValidaÃ§Ã£o dos Dados**
- Campos obrigatÃ³rios sÃ£o validados.
- Datas devem ter um formato vÃ¡lido (`YYYYMMDD`).
- Valores financeiros sÃ£o normalizados para reais (divisÃ£o por 100).
- O CPF/CNPJ Ã© tratado para aceitar 11 ou 14 dÃ­gitos.

### **3ï¸âƒ£ PersistÃªncia no PostgreSQL**
- Foi criada uma tabela `pagamentos` com os seguintes campos:
  ```sql
  CREATE TABLE pagamentos (
      id SERIAL PRIMARY KEY,
      banco VARCHAR(3) NOT NULL,
      nosso_numero VARCHAR(10) NOT NULL,
      numero_documento VARCHAR(10) NOT NULL,
      data_vencimento DATE NOT NULL,
      valor_titulo NUMERIC(10,2) NOT NULL,
      data_pagamento DATE NOT NULL,
      valor_pago NUMERIC(10,2) NOT NULL,
      cpf_cnpj VARCHAR(15) NOT NULL,
      nome_pagador VARCHAR(30) NOT NULL
  );
  ```
- Utilizamos **SQLAlchemy** para manipulaÃ§Ã£o dos dados de forma segura e eficiente.

### **4ï¸âƒ£ PublicaÃ§Ã£o no Apache Kafka**
- Os pagamentos sÃ£o publicados no **tÃ³pico `pagamentos`** para garantir escalabilidade.
- **Kafka-Python** Ã© usado para a comunicaÃ§Ã£o entre produtores e consumidores.

### **5ï¸âƒ£ OrquestraÃ§Ã£o com Dagster**
- Criamos um pipeline no **Dagster** para processar os arquivos diariamente.
- O job `processamento_cnab_job()` executa o processo completo de forma automatizada.

### **6ï¸âƒ£ Monitoramento e Logging**
- Utilizamos **Prometheus** para coletar mÃ©tricas do sistema.
- **Grafana** exibe grÃ¡ficos de processamento e alertas.
- O sistema gera logs estruturados para fÃ¡cil diagnÃ³stico de erros.

---

## ğŸ› ï¸ Como Rodar o Projeto

### **1ï¸âƒ£ Subir os ServiÃ§os**
```bash
docker-compose up -d
```

### **2ï¸âƒ£ Criar o TÃ³pico Kafka**
```bash
docker exec -it kafka kafka-topics.sh --create --topic pagamentos --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1
```

### **3ï¸âƒ£ Executar o Processamento**
```bash
python cnab200_parser.py
```

### **4ï¸âƒ£ Monitorar os Logs**
```bash
tail -f cnab.log
```

---

## ğŸ“Š VisualizaÃ§Ã£o dos Dados
### **Metabase**
1. Acesse **[http://localhost:3000](http://localhost:3000)**.
2. Conecte ao PostgreSQL e selecione a tabela `pagamentos`.
3. Crie um **grÃ¡fico de valores pagos por dia**.

### **Grafana**
1. Acesse **[http://localhost:3001](http://localhost:3001)**.
2. Conecte ao Prometheus.
3. Adicione mÃ©tricas de processamento do CNAB200.

---

## ğŸš€ PrÃ³ximos Passos
âœ… Criar **alertas no Grafana** caso a quantidade de registros seja menor que o esperado.
âœ… Implementar **retries** em falhas de conexÃ£o com Kafka ou PostgreSQL.
âœ… Melhorar a **resiliÃªncia** com filas distribuÃ­das no Kafka.

Caso tenha dÃºvidas ou sugestÃµes, sinta-se Ã  vontade para abrir uma **issue**! ğŸ¯

